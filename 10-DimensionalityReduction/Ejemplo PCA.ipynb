{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134abe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vn55le3/Library/Python/3.9/lib/python/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X = (mnist.data/255.0).astype(float)\n",
    "y = mnist.target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c1afc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f41c528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 154)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pcs=pca.fit_transform(X)\n",
    "pcs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1df75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza  0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1381\n",
      "           1       0.90      0.96      0.93      1575\n",
      "           2       0.85      0.80      0.82      1398\n",
      "           3       0.79      0.82      0.80      1428\n",
      "           4       0.84      0.87      0.85      1365\n",
      "           5       0.76      0.69      0.72      1263\n",
      "           6       0.89      0.92      0.90      1375\n",
      "           7       0.86      0.90      0.88      1459\n",
      "           8       0.81      0.78      0.79      1365\n",
      "           9       0.80      0.73      0.76      1391\n",
      "\n",
      "    accuracy                           0.84     14000\n",
      "   macro avg       0.84      0.84      0.84     14000\n",
      "weighted avg       0.84      0.84      0.84     14000\n",
      "\n",
      "Varianza  0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1381\n",
      "           1       0.92      0.97      0.95      1575\n",
      "           2       0.88      0.84      0.86      1398\n",
      "           3       0.85      0.86      0.85      1428\n",
      "           4       0.87      0.89      0.88      1365\n",
      "           5       0.80      0.76      0.78      1263\n",
      "           6       0.91      0.94      0.92      1375\n",
      "           7       0.90      0.92      0.91      1459\n",
      "           8       0.85      0.80      0.82      1365\n",
      "           9       0.82      0.80      0.81      1391\n",
      "\n",
      "    accuracy                           0.87     14000\n",
      "   macro avg       0.87      0.87      0.87     14000\n",
      "weighted avg       0.87      0.87      0.87     14000\n",
      "\n",
      "Varianza  0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      1381\n",
      "           1       0.93      0.97      0.95      1575\n",
      "           2       0.91      0.86      0.88      1398\n",
      "           3       0.87      0.87      0.87      1428\n",
      "           4       0.89      0.89      0.89      1365\n",
      "           5       0.83      0.80      0.82      1263\n",
      "           6       0.92      0.95      0.94      1375\n",
      "           7       0.91      0.92      0.92      1459\n",
      "           8       0.85      0.82      0.84      1365\n",
      "           9       0.86      0.84      0.85      1391\n",
      "\n",
      "    accuracy                           0.89     14000\n",
      "   macro avg       0.89      0.89      0.89     14000\n",
      "weighted avg       0.89      0.89      0.89     14000\n",
      "\n",
      "Varianza  0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1381\n",
      "           1       0.94      0.97      0.96      1575\n",
      "           2       0.92      0.88      0.90      1398\n",
      "           3       0.89      0.88      0.89      1428\n",
      "           4       0.91      0.91      0.91      1365\n",
      "           5       0.87      0.83      0.85      1263\n",
      "           6       0.93      0.96      0.95      1375\n",
      "           7       0.92      0.94      0.93      1459\n",
      "           8       0.87      0.85      0.86      1365\n",
      "           9       0.88      0.86      0.87      1391\n",
      "\n",
      "    accuracy                           0.91     14000\n",
      "   macro avg       0.91      0.91      0.91     14000\n",
      "weighted avg       0.91      0.91      0.91     14000\n",
      "\n",
      "Varianza  0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1381\n",
      "           1       0.95      0.98      0.96      1575\n",
      "           2       0.93      0.89      0.91      1398\n",
      "           3       0.90      0.89      0.90      1428\n",
      "           4       0.92      0.92      0.92      1365\n",
      "           5       0.87      0.85      0.86      1263\n",
      "           6       0.93      0.96      0.95      1375\n",
      "           7       0.93      0.95      0.94      1459\n",
      "           8       0.88      0.85      0.87      1365\n",
      "           9       0.89      0.87      0.88      1391\n",
      "\n",
      "    accuracy                           0.91     14000\n",
      "   macro avg       0.91      0.91      0.91     14000\n",
      "weighted avg       0.91      0.91      0.91     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lista=[0.60,0.70,0.80,0.90,0.95]\n",
    "for i in lista:\n",
    "    pca = PCA(n_components=i)\n",
    "    pcs=pca.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(pcs, y, random_state=42, \n",
    "                                                        test_size=0.2, \n",
    "                                                        stratify=y)\n",
    "    log_reg = LogisticRegression(solver='liblinear')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred=log_reg.predict(X_test)\n",
    "    print(\"Varianza \",i)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
